"""
X·ª¨ L√ù PDF SCAN - PH√ÅT HI·ªÜN V√ôNG ·∫¢NH TRONG TRANG
D√†nh cho c√°c PDF ƒë∆∞·ª£c scan (m·ªói trang l√† 1 ·∫£nh l·ªõn)
"""

import os
import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple
from pdf2image import convert_from_path
from PIL import Image
import json
import fitz  # PyMuPDF


class ScannedPDFImageDetector:
    """Ph√°t hi·ªán v√πng ·∫£nh trong PDF scan"""
    
    def __init__(self, min_width=150, min_height=150):
        self.min_width = min_width
        self.min_height = min_height
        
    def is_scanned_pdf(self, pdf_path: str) -> bool:
        """
        Ki·ªÉm tra PDF c√≥ ph·∫£i scan kh√¥ng
        N·∫øu m·ªói trang ch·ªâ c√≥ 1 ·∫£nh l·ªõn = PDF scan
        """
        try:
            doc = fitz.open(pdf_path)
            
            # L·∫•y v√†i trang ƒë·∫ßu ƒë·ªÉ test
            pages_to_check = min(3, len(doc))
            
            for page_num in range(pages_to_check):
                page = doc[page_num]
                images = page.get_images(full=True)
                
                # N·∫øu trang c√≥ nhi·ªÅu h∆°n 1 ·∫£nh = kh√¥ng ph·∫£i scan ƒë∆°n gi·∫£n
                if len(images) > 1:
                    doc.close()
                    return False
                
                # N·∫øu c√≥ 1 ·∫£nh, ki·ªÉm tra k√≠ch th∆∞·ªõc
                if len(images) == 1:
                    xref = images[0][0]
                    base_image = doc.extract_image(xref)
                    img_width = base_image["width"]
                    img_height = base_image["height"]
                    
                    page_rect = page.rect
                    page_width = page_rect.width
                    page_height = page_rect.height
                    
                    # N·∫øu ·∫£nh chi·∫øm g·∫ßn nh∆∞ to√†n b·ªô trang = scan
                    if img_width > page_width * 0.9 and img_height > page_height * 0.9:
                        continue
                    else:
                        doc.close()
                        return False
            
            doc.close()
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è  L·ªói ki·ªÉm tra PDF: {e}")
            return False
    
    def preprocess_scanned_page(self, image: np.ndarray) -> np.ndarray:
        """
        Ti·ªÅn x·ª≠ l√Ω trang scan ƒë·ªÉ ph√°t hi·ªán v√πng ·∫£nh t·ªët h∆°n
        """
        # Chuy·ªÉn sang grayscale
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image.copy()
        
        # Kh·ª≠ nhi·ªÖu
        denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
        
        # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(denoised)
        
        return enhanced
    
    def detect_image_regions_advanced(self, image: np.ndarray) -> List[Dict]:
        """
        Ph√°t hi·ªán v√πng ·∫£nh n√¢ng cao cho PDF scan
        S·ª≠ d·ª•ng nhi·ªÅu k·ªπ thu·∫≠t k·∫øt h·ª£p
        """
        h, w = image.shape[:2]
        
        # Ti·ªÅn x·ª≠ l√Ω
        processed = self.preprocess_scanned_page(image)
        
        # PH∆Ø∆†NG PH√ÅP 1: Edge Detection + Contours
        regions_edge = self._detect_by_edges(processed, image)
        
        # PH∆Ø∆†NG PH√ÅP 2: Color/Texture Analysis
        regions_texture = self._detect_by_texture(image)
        
        # PH∆Ø∆†NG PH√ÅP 3: Connected Components
        regions_components = self._detect_by_components(processed, image)
        
        # K·∫øt h·ª£p c√°c ph∆∞∆°ng ph√°p
        all_regions = regions_edge + regions_texture + regions_components
        
        # Lo·∫°i b·ªè tr√πng l·∫∑p v√† merge overlapping boxes
        merged_regions = self._merge_overlapping_regions(all_regions, image)
        
        # L·ªçc v√† s·∫Øp x·∫øp
        filtered = [r for r in merged_regions if self._is_valid_image_region(r, image)]
        filtered.sort(key=lambda r: (r['bbox'][1], r['bbox'][0]))
        
        return filtered
    
    def _detect_by_edges(self, processed: np.ndarray, original: np.ndarray) -> List[Dict]:
        """Ph√°t hi·ªán b·∫±ng edge detection"""
        regions = []
        
        # Canny edge detection
        edges = cv2.Canny(processed, 30, 100)
        
        # Dilate ƒë·ªÉ k·∫øt n·ªëi c√°c c·∫°nh g·∫ßn nhau
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        dilated = cv2.dilate(edges, kernel, iterations=2)
        
        # T√¨m contours
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            
            if w < self.min_width or h < self.min_height:
                continue
            
            # T√≠nh c√°c ƒë·∫∑c tr∆∞ng
            area = w * h
            contour_area = cv2.contourArea(contour)
            solidity = contour_area / area if area > 0 else 0
            aspect_ratio = w / h if h > 0 else 0
            
            # L·ªçc: ·∫£nh th∆∞·ªùng c√≥ ƒë∆∞·ªùng vi·ªÅn r√µ r√†ng
            if solidity > 0.5:
                confidence = self._calculate_confidence(
                    original[y:y+h, x:x+w], 'edge', solidity, aspect_ratio
                )
                
                regions.append({
                    'bbox': (x, y, w, h),
                    'confidence': confidence,
                    'method': 'edge',
                    'solidity': solidity
                })
        
        return regions
    
    def _detect_by_texture(self, image: np.ndarray) -> List[Dict]:
        """Ph√°t hi·ªán b·∫±ng ph√¢n t√≠ch texture"""
        regions = []
        
        # Chuy·ªÉn sang grayscale
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image
        
        # T√≠nh variance ƒë·ªÉ ph√°t hi·ªán v√πng c√≥ nhi·ªÅu chi ti·∫øt
        # ·∫¢nh th∆∞·ªùng c√≥ variance cao h∆°n text
        window_size = 50
        variance_map = np.zeros_like(gray, dtype=np.float32)
        
        for i in range(0, gray.shape[0] - window_size, window_size):
            for j in range(0, gray.shape[1] - window_size, window_size):
                window = gray[i:i+window_size, j:j+window_size]
                variance_map[i:i+window_size, j:j+window_size] = np.var(window)
        
        # Threshold: v√πng c√≥ variance cao = c√≥ th·ªÉ l√† ·∫£nh
        _, texture_mask = cv2.threshold(
            variance_map.astype(np.uint8), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
        )
        
        # Morphology ƒë·ªÉ l√†m s·∫°ch
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 20))
        texture_mask = cv2.morphologyEx(texture_mask, cv2.MORPH_CLOSE, kernel)
        
        # T√¨m contours
        contours, _ = cv2.findContours(texture_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            
            if w < self.min_width or h < self.min_height:
                continue
            
            confidence = self._calculate_confidence(
                image[y:y+h, x:x+w], 'texture', 0, w/h if h > 0 else 0
            )
            
            regions.append({
                'bbox': (x, y, w, h),
                'confidence': confidence,
                'method': 'texture'
            })
        
        return regions
    
    def _detect_by_components(self, processed: np.ndarray, original: np.ndarray) -> List[Dict]:
        """Ph√°t hi·ªán b·∫±ng connected components"""
        regions = []
        
        # Threshold adaptive
        binary = cv2.adaptiveThreshold(
            processed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY_INV, 21, 10
        )
        
        # Lo·∫°i b·ªè text b·∫±ng morphology
        # Text th∆∞·ªùng c√≥ k√≠ch th∆∞·ªõc nh·ªè v√† m·ªèng
        kernel_small = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        without_text = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_small)
        
        # K·∫øt n·ªëi c√°c th√†nh ph·∫ßn g·∫ßn nhau
        kernel_large = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))
        connected = cv2.morphologyEx(without_text, cv2.MORPH_CLOSE, kernel_large)
        
        # T√¨m connected components
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(connected, connectivity=8)
        
        for i in range(1, num_labels):  # B·ªè background (0)
            x = stats[i, cv2.CC_STAT_LEFT]
            y = stats[i, cv2.CC_STAT_TOP]
            w = stats[i, cv2.CC_STAT_WIDTH]
            h = stats[i, cv2.CC_STAT_HEIGHT]
            area = stats[i, cv2.CC_STAT_AREA]
            
            if w < self.min_width or h < self.min_height:
                continue
            
            # T√≠nh solidity
            bbox_area = w * h
            solidity = area / bbox_area if bbox_area > 0 else 0
            
            if solidity > 0.3:  # L·ªçc v√πng qu√° th∆∞a
                confidence = self._calculate_confidence(
                    original[y:y+h, x:x+w], 'component', solidity, w/h if h > 0 else 0
                )
                
                regions.append({
                    'bbox': (x, y, w, h),
                    'confidence': confidence,
                    'method': 'component',
                    'solidity': solidity
                })
        
        return regions
    
    def _calculate_confidence(self, region: np.ndarray, method: str,
                             solidity: float, aspect_ratio: float) -> float:
        """T√≠nh confidence score"""
        confidence = 0.0
        
        # Base confidence theo method
        method_weights = {
            'edge': 0.3,
            'texture': 0.2,
            'component': 0.25
        }
        confidence += method_weights.get(method, 0.2)
        
        # Solidity
        if solidity > 0.8:
            confidence += 0.2
        elif solidity > 0.6:
            confidence += 0.15
        
        # Aspect ratio (·∫£nh th∆∞·ªùng kh√¥ng qu√° m√©o)
        if 0.3 < aspect_ratio < 3.0:
            confidence += 0.15
        
        # K√≠ch th∆∞·ªõc
        h, w = region.shape[:2]
        area = h * w
        if area > 100000:
            confidence += 0.2
        elif area > 50000:
            confidence += 0.15
        elif area > 20000:
            confidence += 0.1
        
        # Ph√¢n t√≠ch chi ti·∫øt region
        if len(region.shape) == 3:
            gray = cv2.cvtColor(region, cv2.COLOR_RGB2GRAY)
        else:
            gray = region
        
        # Edge density (·∫£nh c√≥ nhi·ªÅu c·∫°nh)
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        if edge_density > 0.1:
            confidence += 0.1
        
        # Color variance (·∫£nh th∆∞·ªùng ƒëa s·∫Øc m√†u h∆°n text)
        if len(region.shape) == 3:
            std_per_channel = [np.std(region[:,:,i]) for i in range(3)]
            if np.mean(std_per_channel) > 30:
                confidence += 0.1
        
        return min(confidence, 1.0)
    
    def _merge_overlapping_regions(self, regions: List[Dict], 
                                  image: np.ndarray, 
                                  overlap_threshold: float = 0.5) -> List[Dict]:
        """Merge c√°c region tr√πng l·∫∑p"""
        if not regions:
            return []
        
        # Sort theo confidence
        regions = sorted(regions, key=lambda r: r['confidence'], reverse=True)
        
        merged = []
        used = set()
        
        for i, region1 in enumerate(regions):
            if i in used:
                continue
            
            bbox1 = region1['bbox']
            x1, y1, w1, h1 = bbox1
            
            # T√¨m c√°c region overlap
            overlapping = [region1]
            
            for j, region2 in enumerate(regions[i+1:], i+1):
                if j in used:
                    continue
                
                bbox2 = region2['bbox']
                x2, y2, w2, h2 = bbox2
                
                # T√≠nh IoU (Intersection over Union)
                iou = self._calculate_iou(bbox1, bbox2)
                
                if iou > overlap_threshold:
                    overlapping.append(region2)
                    used.add(j)
            
            # Merge t·∫•t c·∫£ overlapping regions
            if len(overlapping) > 1:
                merged_bbox = self._merge_bboxes([r['bbox'] for r in overlapping])
                merged_confidence = max(r['confidence'] for r in overlapping)
            else:
                merged_bbox = bbox1
                merged_confidence = region1['confidence']
            
            merged.append({
                'bbox': merged_bbox,
                'confidence': merged_confidence,
                'method': 'merged' if len(overlapping) > 1 else region1.get('method', 'unknown')
            })
            
            used.add(i)
        
        return merged
    
    def _calculate_iou(self, bbox1: Tuple, bbox2: Tuple) -> float:
        """T√≠nh Intersection over Union"""
        x1, y1, w1, h1 = bbox1
        x2, y2, w2, h2 = bbox2
        
        # T·ªça ƒë·ªô intersection
        xi1 = max(x1, x2)
        yi1 = max(y1, y2)
        xi2 = min(x1 + w1, x2 + w2)
        yi2 = min(y1 + h1, y2 + h2)
        
        # Di·ªán t√≠ch intersection
        inter_width = max(0, xi2 - xi1)
        inter_height = max(0, yi2 - yi1)
        inter_area = inter_width * inter_height
        
        # Di·ªán t√≠ch union
        area1 = w1 * h1
        area2 = w2 * h2
        union_area = area1 + area2 - inter_area
        
        return inter_area / union_area if union_area > 0 else 0
    
    def _merge_bboxes(self, bboxes: List[Tuple]) -> Tuple:
        """Merge nhi·ªÅu bounding boxes th√†nh 1"""
        x_min = min(bbox[0] for bbox in bboxes)
        y_min = min(bbox[1] for bbox in bboxes)
        x_max = max(bbox[0] + bbox[2] for bbox in bboxes)
        y_max = max(bbox[1] + bbox[3] for bbox in bboxes)
        
        return (x_min, y_min, x_max - x_min, y_max - y_min)
    
    def _is_valid_image_region(self, region: Dict, image: np.ndarray) -> bool:
        """Ki·ªÉm tra region c√≥ ph·∫£i ·∫£nh th·ª±c s·ª± kh√¥ng"""
        x, y, w, h = region['bbox']
        
        # Ki·ªÉm tra k√≠ch th∆∞·ªõc
        if w < self.min_width or h < self.min_height:
            return False
        
        # Kh√¥ng qu√° l·ªõn (kh√¥ng ph·∫£i to√†n trang)
        img_h, img_w = image.shape[:2]
        if w > img_w * 0.95 and h > img_h * 0.95:
            return False
        
        # Confidence t·ªëi thi·ªÉu
        if region['confidence'] < 0.4:
            return False
        
        # Aspect ratio h·ª£p l√Ω
        aspect_ratio = w / h if h > 0 else 0
        if aspect_ratio < 0.1 or aspect_ratio > 10:
            return False
        
        return True
    
    def process_scanned_pdf(self, pdf_path: str, output_dir: str, 
                          dpi: int = 300, visualize: bool = True) -> Dict:
        """
        X·ª≠ l√Ω PDF scan ho√†n ch·ªânh
        
        Returns:
            Dict v·ªõi th·ªëng k√™ v√† danh s√°ch images
        """
        print(f"\nüìÑ X·ª≠ l√Ω PDF scan: {os.path.basename(pdf_path)}")
        
        # Ki·ªÉm tra c√≥ ph·∫£i PDF scan kh√¥ng
        is_scanned = self.is_scanned_pdf(pdf_path)
        print(f"   Lo·∫°i: {'PDF Scan' if is_scanned else 'PDF Digital'}")
        
        # Convert PDF sang images
        print(f"   üîÑ Chuy·ªÉn ƒë·ªïi PDF (DPI: {dpi})...")
        pdf_images = convert_from_path(pdf_path, dpi=dpi)
        
        # X·ª≠ l√Ω t·ª´ng trang
        all_results = []
        total_images = 0
        
        for page_num, page_img in enumerate(pdf_images, 1):
            print(f"   üìë Trang {page_num}/{len(pdf_images)}", end='\r')
            
            img_array = np.array(page_img)
            
            # Ph√°t hi·ªán v√πng ·∫£nh
            detected_regions = self.detect_image_regions_advanced(img_array)
            
            # L∆∞u th√¥ng tin
            page_result = {
                'page': page_num,
                'regions': detected_regions,
                'count': len(detected_regions)
            }
            all_results.append(page_result)
            total_images += len(detected_regions)
            
            # Extract v√† l∆∞u t·ª´ng ·∫£nh
            for idx, region in enumerate(detected_regions, 1):
                x, y, w, h = region['bbox']
                extracted_img = img_array[y:y+h, x:x+w]
                
                # L∆∞u ·∫£nh
                img_filename = f"page_{page_num:03d}_img_{idx:02d}.png"
                img_path = os.path.join(output_dir, 'extracted_images', img_filename)
                os.makedirs(os.path.dirname(img_path), exist_ok=True)
                
                img_bgr = cv2.cvtColor(extracted_img, cv2.COLOR_RGB2BGR)
                cv2.imwrite(img_path, img_bgr)
                
                # Th√™m th√¥ng tin file v√†o region
                region['filename'] = img_filename
            
            # Visualization
            if visualize and detected_regions:
                vis_img = img_array.copy()
                for region in detected_regions:
                    x, y, w, h = region['bbox']
                    conf = region['confidence']
                    
                    # V·∫Ω rectangle
                    cv2.rectangle(vis_img, (x, y), (x+w, y+h), (0, 255, 0), 3)
                    
                    # Label
                    label = f"{conf:.2f}"
                    cv2.putText(vis_img, label, (x, y-10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                
                # L∆∞u visualization
                vis_path = os.path.join(output_dir, 'bbox_visualizations', 
                                       f'page_{page_num:03d}_bbox.png')
                os.makedirs(os.path.dirname(vis_path), exist_ok=True)
                vis_bgr = cv2.cvtColor(vis_img, cv2.COLOR_RGB2BGR)
                cv2.imwrite(vis_path, vis_bgr)
        
        print(f"\n   ‚úÖ ƒê√£ ph√°t hi·ªán {total_images} v√πng ·∫£nh")
        
        # L∆∞u metadata
        metadata = {
            'pdf_file': os.path.basename(pdf_path),
            'is_scanned': is_scanned,
            'total_pages': len(pdf_images),
            'total_images': total_images,
            'dpi': dpi,
            'pages': all_results
        }
        
        metadata_path = os.path.join(output_dir, 'scanned_metadata.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        return metadata


def main():
    """Demo s·ª≠ d·ª•ng"""
    
    print("=" * 70)
    print("üîç PDF SCAN - PH√ÅT HI·ªÜN V√ôNG ·∫¢NH")
    print("=" * 70)
    
    # C·∫•u h√¨nh
    pdf_file = "input/scanned_document.pdf"
    output_dir = "output/scanned_test"
    
    if not os.path.exists(pdf_file):
        print(f"\n‚ùå Kh√¥ng t√¨m th·∫•y: {pdf_file}")
        print("üí° ƒê·∫∑t file PDF scan v√†o th∆∞ m·ª•c input/")
        input("\nNh·∫•n Enter ƒë·ªÉ tho√°t...")
        return
    
    try:
        # Kh·ªüi t·∫°o detector
        detector = ScannedPDFImageDetector(
            min_width=150,   # ƒêi·ªÅu ch·ªânh theo nhu c·∫ßu
            min_height=150
        )
        
        # X·ª≠ l√Ω PDF
        result = detector.process_scanned_pdf(
            pdf_path=pdf_file,
            output_dir=output_dir,
            dpi=300,
            visualize=True
        )
        
        # Th·ªëng k√™
        print("\n" + "=" * 70)
        print("üìä K·∫æT QU·∫¢")
        print("=" * 70)
        print(f"\n‚úÖ T·ªïng s·ªë ·∫£nh: {result['total_images']}")
        print(f"üìÑ T·ªïng s·ªë trang: {result['total_pages']}")
        print(f"\nüìë Chi ti·∫øt:")
        
        for page_data in result['pages']:
            if page_data['count'] > 0:
                print(f"   Trang {page_data['page']}: {page_data['count']} ·∫£nh")
        
        print(f"\nüìÇ K·∫øt qu·∫£:")
        print(f"   - ·∫¢nh: {output_dir}/extracted_images/")
        print(f"   - Visualization: {output_dir}/bbox_visualizations/")
        print(f"   - Metadata: {output_dir}/scanned_metadata.json")
        
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
    
    input("\n\nNh·∫•n Enter ƒë·ªÉ tho√°t...")


if __name__ == "__main__":
    main()